{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Read the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "bc1536a2d8fbce0795614d67d9205b4ab2baf132",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set has  (72983, 34)\n",
      "test set has  (48707, 33)\n",
      "remove one column from the training set\n",
      "merge training set and test set to all_data\n",
      "all_data has  (121690, 33)\n"
     ]
    }
   ],
   "source": [
    "# Read the data into dataframes\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('training.csv')\n",
    "print (\"training set has \", train_df.shape)\n",
    "test_df = pd.read_csv('test.csv')\n",
    "print (\"test set has \", test_df.shape)\n",
    "ntest = test_df.shape[0]\n",
    "\n",
    "print (\"remove one column from the training set\")\n",
    "print (\"merge training set and test set to all_data\")\n",
    "\n",
    "Ytrain = train_df['IsBadBuy']\n",
    "train_df = train_df.drop(columns=['IsBadBuy'])\n",
    "\n",
    "# Put all data together so we can wrangle all the data at the same time\n",
    "all_data = pd.concat([train_df, test_df], ignore_index=True)\n",
    "print (\"all_data has \", all_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RefId                                     0\n",
       "PurchDate                                 0\n",
       "Auction                                   0\n",
       "VehYear                                   0\n",
       "VehicleAge                                0\n",
       "Make                                      0\n",
       "Model                                     0\n",
       "Trim                                   3910\n",
       "SubModel                                 13\n",
       "Color                                    12\n",
       "Transmission                             12\n",
       "WheelTypeID                            5357\n",
       "WheelType                              5362\n",
       "VehOdo                                    0\n",
       "Nationality                              12\n",
       "Size                                     12\n",
       "TopThreeAmericanName                     12\n",
       "MMRAcquisitionAuctionAveragePrice        28\n",
       "MMRAcquisitionAuctionCleanPrice          28\n",
       "MMRAcquisitionRetailAveragePrice         28\n",
       "MMRAcquisitonRetailCleanPrice            28\n",
       "MMRCurrentAuctionAveragePrice           458\n",
       "MMRCurrentAuctionCleanPrice             458\n",
       "MMRCurrentRetailAveragePrice            458\n",
       "MMRCurrentRetailCleanPrice              458\n",
       "PRIMEUNIT                            115755\n",
       "AUCGUART                             115755\n",
       "BYRNO                                     0\n",
       "VNZIP1                                    0\n",
       "VNST                                      0\n",
       "VehBCost                                  0\n",
       "IsOnlineSale                              0\n",
       "WarrantyCost                              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5e14a4a6c7dc7d5fbd21e58e43d71256357733f4"
   },
   "source": [
    "###  Drop the unimportant stuff\n",
    "\n",
    "There are too many missing data in \"PRIMEUNIT\" and \"AUCGUART\", so we can just remove these features.\n",
    "Also \"RefId\" has nothing to do but only the ID number that can be removed as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "b37b06030bc2581722bd2d98752e498fc5b6627f",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_data.drop(labels='AUCGUART', axis='columns', inplace=True)\n",
    "all_data.drop(labels='PRIMEUNIT', axis='columns', inplace=True)\n",
    "all_data.drop(labels='RefId', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7e55734ef4c3fa2460d01deaa351113e66c5ee74"
   },
   "source": [
    "### Deal with missing values\n",
    "\n",
    "<p>Let's take a look at what missing values we'll have to handle.</p> For the numeric variable, replace null by median and for the category variable, most popular value is used to fill null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PurchDate                            0\n",
       "Auction                              0\n",
       "VehYear                              0\n",
       "VehicleAge                           0\n",
       "Make                                 0\n",
       "Model                                0\n",
       "Trim                                 0\n",
       "SubModel                             0\n",
       "Color                                0\n",
       "Transmission                         0\n",
       "WheelTypeID                          0\n",
       "WheelType                            0\n",
       "VehOdo                               0\n",
       "Nationality                          0\n",
       "Size                                 0\n",
       "TopThreeAmericanName                 0\n",
       "MMRAcquisitionAuctionAveragePrice    0\n",
       "MMRAcquisitionAuctionCleanPrice      0\n",
       "MMRAcquisitionRetailAveragePrice     0\n",
       "MMRAcquisitonRetailCleanPrice        0\n",
       "MMRCurrentAuctionAveragePrice        0\n",
       "MMRCurrentAuctionCleanPrice          0\n",
       "MMRCurrentRetailAveragePrice         0\n",
       "MMRCurrentRetailCleanPrice           0\n",
       "BYRNO                                0\n",
       "VNZIP1                               0\n",
       "VNST                                 0\n",
       "VehBCost                             0\n",
       "IsOnlineSale                         0\n",
       "WarrantyCost                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_isnull = all_data.columns[all_data.isnull().any()]\n",
    "for col in all_isnull:\n",
    "    try:\n",
    "all_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with category variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PurchDate', 'Auction', 'Make', 'Model', 'Trim', 'SubModel', 'Color', 'Transmission', 'WheelType', 'Nationality', 'Size', 'TopThreeAmericanName', 'VNST']\n",
      "PurchDate 519\n",
      "Auction 3\n",
      "['ADESA' 'OTHER' 'MANHEIM']\n",
      "Make 33\n",
      "['MAZDA' 'DODGE' 'FORD' 'MITSUBISHI' 'KIA' 'GMC' 'NISSAN' 'CHEVROLET'\n",
      " 'SATURN' 'CHRYSLER' 'MERCURY' 'HYUNDAI' 'TOYOTA' 'PONTIAC' 'SUZUKI'\n",
      " 'JEEP' 'HONDA' 'OLDSMOBILE' 'BUICK' 'SCION' 'VOLKSWAGEN' 'ISUZU'\n",
      " 'LINCOLN' 'MINI' 'SUBARU' 'CADILLAC' 'VOLVO' 'INFINITI' 'PLYMOUTH'\n",
      " 'LEXUS' 'ACURA' 'TOYOTA SCION' 'HUMMER']\n",
      "Model 1130\n",
      "Trim 137\n",
      "SubModel 933\n",
      "Color 17\n",
      "['RED' 'WHITE' 'MAROON' 'SILVER' 'BLACK' 'GOLD' 'GREY' 'BLUE' 'BEIGE'\n",
      " 'PURPLE' 'ORANGE' 'GREEN' 'BROWN' 'YELLOW' 'NOT AVAIL' 'OTHER' 'PINK']\n",
      "Transmission 3\n",
      "['AUTO' 'MANUAL' 'Manual']\n",
      "WheelType 3\n",
      "['Alloy' 'Covers' 'Special']\n",
      "Nationality 4\n",
      "['OTHER ASIAN' 'AMERICAN' 'TOP LINE ASIAN' 'OTHER']\n",
      "Size 12\n",
      "['MEDIUM' 'LARGE TRUCK' 'COMPACT' 'LARGE' 'VAN' 'MEDIUM SUV' 'LARGE SUV'\n",
      " 'SPECIALTY' 'SPORTS' 'CROSSOVER' 'SMALL SUV' 'SMALL TRUCK']\n",
      "TopThreeAmericanName 4\n",
      "['OTHER' 'CHRYSLER' 'FORD' 'GM']\n",
      "VNST 38\n",
      "['FL' 'VA' 'IA' 'AR' 'MN' 'TN' 'PA' 'OH' 'AL' 'MI' 'TX' 'IL' 'MA' 'AZ'\n",
      " 'GA' 'NC' 'MD' 'CA' 'UT' 'OR' 'SC' 'CO' 'ID' 'NV' 'WV' 'MS' 'OK' 'NM'\n",
      " 'LA' 'IN' 'MO' 'WA' 'NH' 'NJ' 'NY' 'NE' 'KY' 'WI']\n"
     ]
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "nonList = list(all_data.select_dtypes(include=[np.object]))\n",
    "print (nonList)\n",
    "\n",
    "all_data2 = all_data.copy()\n",
    "\n",
    "for this_label in nonList:\n",
    "    \n",
    "    encoder = ce.BinaryEncoder(cols=[this_label])\n",
    "    \n",
    "    all_data2 = encoder.fit_transform(all_data2)    \n",
    "    \n",
    "    print (this_label, len(all_data[this_label].unique()))\n",
    "    if (len(all_data[this_label].unique()) < 40):\n",
    "        print (all_data[this_label].unique())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "da3da259df43ee819735f558d677348c33641d49"
   },
   "source": [
    "###  Diving in (machine learning)\n",
    "\n",
    "<p>Now that the data has been cleaned, we can try to find a model that works well for making our predictions. We'll also load in some classifiers which we will compare.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "45e81048fd2b50e44ca687582f9900520d1e6392",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "Xtrain = all_data2.head(len(Ytrain))\n",
    "\n",
    "RFC = RandomForestClassifier()\n",
    "Ada = AdaBoostClassifier()\n",
    "KNN = KNeighborsClassifier()\n",
    "classifiers = [RFC, Ada, KNN]\n",
    "clf_names = ['Random Forest', 'AdaBoost', 'K Nearest Neighbors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2573510f0de967cf3741b0963345784f32caaa30"
   },
   "source": [
    "<p>For this analysis, we'll only be comparing across three classifiers: Random Forest, AdaBoost, and K Nearest Neighbors. For more information on other potential (or more complicated) classifiers I invite you to check out the other kernels posted by those who top the leaderboards for this competition.</p>\n",
    "\n",
    "<p>For each of these classifiers, we'll want to make sure we create the models with the optimal parameters. We can do this with a Grid Search. We define the set of parameters we want to scan for each type of classifier, and then run our grid searches.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "a322b47a7dc1d0147ffbd3fcd3241366fe438af6"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n",
    "\n",
    "# Use kfold as our cross validation\n",
    "kfold = StratifiedKFold(n_splits=4)\n",
    "\n",
    "# Set grid search parameter settings\n",
    "rfc_param_grid = {'max_depth': [None],\n",
    "                 'max_features': [1],\n",
    "                 'min_samples_split': [2],\n",
    "                 'min_samples_leaf': [1],\n",
    "                 'bootstrap': [False],\n",
    "                 'n_estimators': [100],\n",
    "                 'criterion': ['gini']}\n",
    "ada_param_grid = {'n_estimators': [20],\n",
    "                 'learning_rate': [0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "knn_param_grid = {'n_neighbors': [5],\n",
    "                  'weights': ['uniform', 'distance'],\n",
    "                 'leaf_size': [5]}\n",
    "param_grids = [rfc_param_grid, ada_param_grid, knn_param_grid]\n",
    "\n",
    "# Perform grid searches to get estimators with the optimal settings\n",
    "grid_searches = []\n",
    "for i in range(len(classifiers)):\n",
    "    grid_searches.append(GridSearchCV(estimator=classifiers[i], param_grid=param_grids[i], \n",
    "                                      n_jobs=4, cv=kfold, verbose=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d632d4a7bf7c566b139aa09ac56d12cbfdf10116"
   },
   "source": [
    "<p>We'll now want to see the training scores for each of our models and determine which one works the best. We'll fit each model to our training set and add the best scores from each to a list.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "9f8452618656ef1a841d1a7ce1f69478f0d963ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:   36.9s remaining:   36.9s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   38.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 out of  24 | elapsed:   36.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   8 out of   8 | elapsed:  2.4min finished\n"
     ]
    }
   ],
   "source": [
    "# Train the models\n",
    "best_scores = []\n",
    "for i in range(len(grid_searches)):\n",
    "    grid_searches[i].fit(Xtrain, Ytrain)\n",
    "    best_scores.append(grid_searches[i].best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f499d641ff0414737da2c8e64339934c034dd968"
   },
   "source": [
    "<p>Let's see the best scores for each classifier.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "242a20ab1d09bd77b8082086be53cff9c12ce541"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: 0.8746283381061343\n",
      "AdaBoost: 0.8771905786278996\n",
      "K Nearest Neighbors: 0.8560486688680926\n"
     ]
    }
   ],
   "source": [
    "# Best scores\n",
    "for i in range(len(best_scores)):\n",
    "    print(clf_names[i] + \": \" + str(best_scores[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "763ba583c7e203ca3d44f39ce89cfd6d7c0c0e5a"
   },
   "source": [
    "<p>Based on these training scores, it makes the most sense to use the Random Forest Classifier to make the predictions. We'll predict on the test set, and then write the predictions to a csv file for submission.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "b3ca1c1802687ab5e165f0dfcbcc4e06a574604f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done writing to csv\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "Xtest = all_data2.tail(ntest)\n",
    "#Xtest = test_df.drop(columns='RefId', axis='columns')\n",
    "predictions = grid_searches[0].predict(Xtest)\n",
    "\n",
    "# Write predictions to output csv\n",
    "pred_df = pd.DataFrame({'RefId': test_df['RefId'],\n",
    "                        'IsBadBuy': predictions})\n",
    "pred_df.to_csv('predictions.csv', index=False)\n",
    "\n",
    "print(\"Done writing to csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read and check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "bc1536a2d8fbce0795614d67d9205b4ab2baf132",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#from sklearn.utils import resample\n",
    "#from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_df(df, print_null_info):\n",
    "    df_shape = df.shape\n",
    "    print (\"\\nThe dataframe has %s data and %s features\" %(df_shape[0], df_shape[1]))\n",
    "    #\n",
    "    features_obj = list(df.select_dtypes(include=['object']).columns)\n",
    "    print (\"\\nThe number of object features: %s\" %(len(features_obj)))\n",
    "    for feature in features_obj:\n",
    "        if (print_null_info):\n",
    "            num_null = df[feature].isnull().sum()\n",
    "            if (num_null > 0):\n",
    "                print (\"%50s has %8d null values (%7.2f percent)\" %(feature, num_null, num_null/df_shape[0]*100))\n",
    "    #\n",
    "    features_num = list(df.select_dtypes(exclude=['object']).columns)\n",
    "    print (\"\\nThe number of numeric features: %s\" %(len(features_num)))\n",
    "    for feature in features_num:\n",
    "        if (print_null_info):\n",
    "            num_null = df[feature].isnull().sum()\n",
    "            if (num_null > 0):\n",
    "                print (\"%50s has %8d null values (%7.2f percent)\" %(feature, num_null, num_null/df_shape[0]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The dataframe has 72983 data and 34 features\n",
      "\n",
      "The number of object features: 15\n",
      "                                              Trim has     2360 null values (   3.23 percent)\n",
      "                                          SubModel has        8 null values (   0.01 percent)\n",
      "                                             Color has        8 null values (   0.01 percent)\n",
      "                                      Transmission has        9 null values (   0.01 percent)\n",
      "                                         WheelType has     3174 null values (   4.35 percent)\n",
      "                                       Nationality has        5 null values (   0.01 percent)\n",
      "                                              Size has        5 null values (   0.01 percent)\n",
      "                              TopThreeAmericanName has        5 null values (   0.01 percent)\n",
      "                                         PRIMEUNIT has    69564 null values (  95.32 percent)\n",
      "                                          AUCGUART has    69564 null values (  95.32 percent)\n",
      "\n",
      "The number of numeric features: 19\n",
      "                                       WheelTypeID has     3169 null values (   4.34 percent)\n",
      "                 MMRAcquisitionAuctionAveragePrice has       18 null values (   0.02 percent)\n",
      "                   MMRAcquisitionAuctionCleanPrice has       18 null values (   0.02 percent)\n",
      "                  MMRAcquisitionRetailAveragePrice has       18 null values (   0.02 percent)\n",
      "                     MMRAcquisitonRetailCleanPrice has       18 null values (   0.02 percent)\n",
      "                     MMRCurrentAuctionAveragePrice has      315 null values (   0.43 percent)\n",
      "                       MMRCurrentAuctionCleanPrice has      315 null values (   0.43 percent)\n",
      "                      MMRCurrentRetailAveragePrice has      315 null values (   0.43 percent)\n",
      "                        MMRCurrentRetailCleanPrice has      315 null values (   0.43 percent)\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('training.csv')\n",
    "get_info_df(dataset, print_null_info= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([], dtype='int64')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Droping ID\n",
    "feature = \"RefId\"\n",
    "dataset.drop(labels=feature, axis='columns', inplace=True)\n",
    "\n",
    "# Check for duplicated data\n",
    "dataset[dataset.duplicated(keep=False)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_target_bibary(df, target_feature):\n",
    "    unique_target_vals = df[target_feature].unique()\n",
    "    print (\"\\nUnique values of the target:\", unique_target_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values of the target: [0 1]\n"
     ]
    }
   ],
   "source": [
    "check_target_bibary(df=dataset, target_feature='IsBadBuy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_target_balance(df, target_feature):\n",
    "    target_vals = df[target_feature]\n",
    "    len_target_vals = len(target_vals)\n",
    "    sum_target_vals = sum(target_vals)\n",
    "    frac1 = sum_target_vals/ len_target_vals\n",
    "    frac0 = 1-frac1\n",
    "    print (\"fraction of (%s==0): %6.2f\" %(target_feature, frac0*100))\n",
    "    print (\"fraction of (%s==1): %6.2f\" %(target_feature, frac1*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraction of (IsBadBuy==0):  87.70\n",
      "fraction of (IsBadBuy==1):  12.30\n"
     ]
    }
   ],
   "source": [
    "check_target_balance(df=dataset, target_feature='IsBadBuy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_imbalanced_data(df, target_feature):\n",
    "    target_vals = df[target_feature]\n",
    "    len_target_vals = len(target_vals)\n",
    "    n_target_1 = sum(target_vals)\n",
    "    n_target_0 = len_target_vals-n_target_1\n",
    "    #\n",
    "    if (n_target_1 < n_target_0):\n",
    "        df_minor = df[df[target_feature]==1]\n",
    "        df_major = df[df[target_feature]==0]\n",
    "    else:\n",
    "        df_major = df[df[target_feature]==1]\n",
    "        df_minor = df[df[target_feature]==0]\n",
    "    return [df_minor, df_major]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsample, upsample = select_imbalanced_data(df=dataset, target_feature='IsBadBuy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The dataframe has 19203 data and 33 features\n",
      "\n",
      "The number of object features: 15\n",
      "                                              Trim has      598 null values (   3.11 percent)\n",
      "                                          SubModel has        3 null values (   0.02 percent)\n",
      "                                             Color has        3 null values (   0.02 percent)\n",
      "                                      Transmission has        3 null values (   0.02 percent)\n",
      "                                         WheelType has      306 null values (   1.59 percent)\n",
      "                                       Nationality has        3 null values (   0.02 percent)\n",
      "                                              Size has        3 null values (   0.02 percent)\n",
      "                              TopThreeAmericanName has        3 null values (   0.02 percent)\n",
      "                                         PRIMEUNIT has    18191 null values (  94.73 percent)\n",
      "                                          AUCGUART has    18191 null values (  94.73 percent)\n",
      "\n",
      "The number of numeric features: 18\n",
      "                                       WheelTypeID has      306 null values (   1.59 percent)\n",
      "                 MMRAcquisitionAuctionAveragePrice has        5 null values (   0.03 percent)\n",
      "                   MMRAcquisitionAuctionCleanPrice has        5 null values (   0.03 percent)\n",
      "                  MMRAcquisitionRetailAveragePrice has        5 null values (   0.03 percent)\n",
      "                     MMRAcquisitonRetailCleanPrice has        5 null values (   0.03 percent)\n",
      "                     MMRCurrentAuctionAveragePrice has       92 null values (   0.48 percent)\n",
      "                       MMRCurrentAuctionCleanPrice has       92 null values (   0.48 percent)\n",
      "                      MMRCurrentRetailAveragePrice has       92 null values (   0.48 percent)\n",
      "                        MMRCurrentRetailCleanPrice has       92 null values (   0.48 percent)\n",
      "\n",
      "The dataframe has 2693 data and 33 features\n",
      "\n",
      "The number of object features: 15\n",
      "                                              Trim has      109 null values (   4.05 percent)\n",
      "                                         WheelType has      677 null values (  25.14 percent)\n",
      "                                         PRIMEUNIT has     2662 null values (  98.85 percent)\n",
      "                                          AUCGUART has     2662 null values (  98.85 percent)\n",
      "\n",
      "The number of numeric features: 18\n",
      "                                       WheelTypeID has      676 null values (  25.10 percent)\n",
      "                 MMRAcquisitionAuctionAveragePrice has        1 null values (   0.04 percent)\n",
      "                   MMRAcquisitionAuctionCleanPrice has        1 null values (   0.04 percent)\n",
      "                  MMRAcquisitionRetailAveragePrice has        1 null values (   0.04 percent)\n",
      "                     MMRAcquisitonRetailCleanPrice has        1 null values (   0.04 percent)\n",
      "                     MMRCurrentAuctionAveragePrice has        7 null values (   0.26 percent)\n",
      "                       MMRCurrentAuctionCleanPrice has        7 null values (   0.26 percent)\n",
      "                      MMRCurrentRetailAveragePrice has        7 null values (   0.26 percent)\n",
      "                        MMRCurrentRetailCleanPrice has        7 null values (   0.26 percent)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size = 0.3\n",
    "train_up, valid_up = train_test_split(upsample, test_size=test_size)\n",
    "train_down, valid_down = train_test_split(downsample, test_size=test_size)\n",
    "\n",
    "#get_info_df(train_up, print_null_info=False)\n",
    "#get_info_df(valid_up, print_null_info=True)\n",
    "#get_info_df(train_down, print_null_info=False)\n",
    "#get_info_df(valid_down, print_null_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-83c2e1e3354d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhuy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'aa' is not defined"
     ]
    }
   ],
   "source": [
    "huy = aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_major_downsampled = resample(train_df_major, replace=False, n_samples=n_minor, random_state=123)\n",
    "train_data = pd.concat([train_df_major_downsampled, train_df_minor])\n",
    "\n",
    "Ytrain = train_data.IsBadBuy\n",
    "\n",
    "train_data.IsBadBuy.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_num = list(train_data.select_dtypes(include=['float64','int64']).columns)\n",
    "print (col_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the function to plot figures\n",
    "def his_plot(df, features_plot, feature_target, ncolplot, rotang):\n",
    "    nfig = len(features_plot)\n",
    "    nrowplot = np.int(np.ceil(nfig/ncolplot))\n",
    "    fig, axs = plt.subplots(nrowplot, ncolplot, figsize=(16,16))\n",
    "    labels = [feature_target + \" = 1\", feature_target + \" = 0\"]\n",
    "    num = 0\n",
    "    for feature in features_plot:\n",
    "        data_hist = [df[df[feature_target]==1][feature].dropna(), df[df[feature_target]==0][feature].dropna()]\n",
    "        id_row = int(num/ncolplot)\n",
    "        id_col = num-id_row*ncolplot\n",
    "        try:\n",
    "            axs[id_row,id_col].hist(data_hist, label=labels)\n",
    "            axs[id_row,id_col].legend(prop={'size': 10})\n",
    "            axs[id_row,id_col].set_title(feature)\n",
    "            axs[id_row,id_col].xaxis.set_tick_params(rotation=rotang)\n",
    "        except:\n",
    "            axs[id_col].hist(data_hist, label=labels)\n",
    "            axs[id_col].legend(prop={'size': 10})\n",
    "            axs[id_col].set_title(feature)\n",
    "            axs[id_col].xaxis.set_tick_params(rotation=rotang)\n",
    "        num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "his_plot(df=train_data, features_plot=col_num, feature_target='IsBadBuy', ncolplot=4, rotang = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "can_drop = []\n",
    "\n",
    "feature = \"IsOnlineSale\"\n",
    "can_drop.append(feature)\n",
    "train_data.drop(labels=feature, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_num = list(train_data.select_dtypes(include=['float64','int64']).columns)\n",
    "\n",
    "corr = train_data[col_num].corr()\n",
    "\n",
    "plt.figure(figsize = (10,8))\n",
    "\n",
    "sns.heatmap(corr, xticklabels = corr.columns, yticklabels = corr.columns, cmap=\"YlGnBu\", annot=True, fmt=\".1f\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = \"VehYear\"\n",
    "can_drop.append(feature)\n",
    "train_data.drop(labels=feature, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = \"MMRAcquisitionAuctionAveragePrice\"\n",
    "can_drop.append(feature)\n",
    "train_data.drop(labels=feature, axis='columns', inplace=True)\n",
    "\n",
    "feature = \"MMRAcquisitionAuctionCleanPrice\"\n",
    "can_drop.append(feature)\n",
    "train_data.drop(labels=feature, axis='columns', inplace=True)\n",
    "\n",
    "feature = \"MMRAcquisitionRetailAveragePrice\"\n",
    "can_drop.append(feature)\n",
    "train_data.drop(labels=feature, axis='columns', inplace=True)\n",
    "\n",
    "feature = \"MMRAcquisitonRetailCleanPrice\"\n",
    "can_drop.append(feature)\n",
    "train_data.drop(labels=feature, axis='columns', inplace=True)\n",
    "\n",
    "feature = \"MMRCurrentAuctionAveragePrice\"\n",
    "can_drop.append(feature)\n",
    "train_data.drop(labels=feature, axis='columns', inplace=True)\n",
    "\n",
    "feature = \"MMRCurrentAuctionCleanPrice\"\n",
    "can_drop.append(feature)\n",
    "train_data.drop(labels=feature, axis='columns', inplace=True)\n",
    "\n",
    "feature = \"MMRCurrentRetailAveragePrice\"\n",
    "can_drop.append(feature)\n",
    "train_data.drop(labels=feature, axis='columns', inplace=True)\n",
    "\n",
    "feature = \"MMRCurrentRetailCleanPrice\"\n",
    "can_drop.append(feature)\n",
    "train_data.drop(labels=feature, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_num = list(train_data.select_dtypes(include=['float64','int64']).columns)\n",
    "\n",
    "corr = train_data[col_num].corr()\n",
    "\n",
    "plt.figure(figsize = (10,8))\n",
    "\n",
    "sns.heatmap(corr, xticklabels = corr.columns, yticklabels = corr.columns, cmap=\"YlGnBu\", annot=True, fmt=\".1f\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Object variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_object = list(train_data.select_dtypes(include=['object']).columns)\n",
    "print (col_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in col_object:\n",
    "    print (col, \":  the number of unique data: \", len(train_data[col].unique()))\n",
    "    if (len(train_data[col].unique()) < 20):\n",
    "        print (train_data[col].unique())\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "his_plot(df=train_data, features_plot=col_object, feature_target='IsBadBuy', ncolplot=4, rotang = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = \"Transmission\"\n",
    "can_drop.append(feature)\n",
    "train_data.drop(labels=feature, axis='columns', inplace=True)\n",
    "\n",
    "feature = \"PRIMEUNIT\"\n",
    "can_drop.append(feature)\n",
    "train_data.drop(labels=feature, axis='columns', inplace=True)\n",
    "\n",
    "feature = \"AUCGUART\"\n",
    "can_drop.append(feature)\n",
    "train_data.drop(labels=feature, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_object = list(train_data.select_dtypes(include=['object']).columns)\n",
    "print (col_object)\n",
    "\n",
    "df = train_data[col_object]\n",
    "corr = df.apply(lambda x: x.factorize()[0]).corr()\n",
    "\n",
    "plt.figure(figsize = (10,8))\n",
    "\n",
    "sns.heatmap(corr, xticklabels = corr.columns, yticklabels = corr.columns, cmap=\"YlGnBu\", annot=True, fmt=\".1f\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = \"Nationality\"\n",
    "can_drop.append(feature)\n",
    "train_data.drop(labels=feature, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_plot = ['WheelType','WheelTypeID']\n",
    "his_plot(df=train_data, features_plot=col_plot, feature_target='IsBadBuy', ncolplot=2, rotang = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = \"WheelTypeID\"\n",
    "can_drop.append(feature)\n",
    "train_data.drop(labels=feature, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7e55734ef4c3fa2460d01deaa351113e66c5ee74"
   },
   "source": [
    "## 2. Deal with missing values\n",
    "\n",
    "<p>Let's take a look at what missing values we'll have to handle.</p> For the numeric variable, replace null by median and for the category variable, most popular value is used to fill null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_null = train_data.columns[train_data.isnull().any()]\n",
    "for col in all_null:\n",
    "    try:\n",
    "        train_data[col].fillna(train_data[col].mode()[0], inplace=True)\n",
    "    except:\n",
    "        train_data[col].fillna(train_data[col].median(), inplace=True)\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_feature = 'PurchDate'\n",
    "train_data[date_feature] = pd.to_datetime(train_data[date_feature])\n",
    "train_data[date_feature].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"data from:\", train_data[date_feature].min(), \" to:\", train_data[date_feature].max() )\n",
    "print (\"which has total\", train_data[date_feature].max() - train_data[date_feature].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_feature = 'PurchDate'\n",
    "\n",
    "train_data['Year'] = train_data[date_feature].dt.year\n",
    "train_data['Month'] = train_data[date_feature].dt.month\n",
    "train_data['Day'] = train_data[date_feature].dt.day\n",
    "train_data['Day_Name'] = train_data[date_feature].dt.day_name()\n",
    "train_data['Day_Name_Num'] = train_data[date_feature].dt.dayofweek\n",
    "\n",
    "feature = \"PurchDate\"\n",
    "can_drop.append(feature)\n",
    "train_data.drop(labels=feature, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_plot = ['Year', 'Month', 'Day', 'Day_Name', 'Day_Name_Num']\n",
    "his_plot(df=train_data, features_plot=col_plot, feature_target='IsBadBuy', ncolplot=5, rotang = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['sinMonth'] = np.sin(train_data['Month'] * 2.0 *np.pi/12.0)\n",
    "train_data['cosMonth'] = np.cos(train_data['Month'] * 2.0 *np.pi/12.0)\n",
    "#train_data[['sinMonth','cosMonth','Month']].head()\n",
    "\n",
    "train_data['sinDay'] = np.sin(train_data['Day'] * 2.0 *np.pi/30.0)\n",
    "train_data['cosDay'] = np.cos(train_data['Day'] * 2.0 *np.pi/30.0)\n",
    "#train_data[['sinDay','cosDay','Day']].head()\n",
    "\n",
    "train_data['sinDay_Name_Num'] = np.sin(train_data['Day_Name_Num'] * 2.0 *np.pi/30.0)\n",
    "train_data['cosDay_Name_Num'] = np.cos(train_data['Day_Name_Num'] * 2.0 *np.pi/30.0)\n",
    "#train_data[['sinDay_Name_Num','cosDay_Name_Num','Day_Name_Num']].head()\n",
    "\n",
    "\n",
    "feature = \"Month\"\n",
    "can_drop.append(feature)\n",
    "train_data.drop(labels=feature, axis='columns', inplace=True)\n",
    "\n",
    "feature = \"Day\"\n",
    "can_drop.append(feature)\n",
    "train_data.drop(labels=feature, axis='columns', inplace=True)\n",
    "\n",
    "feature = \"Day_Name_Num\"\n",
    "can_drop.append(feature)\n",
    "train_data.drop(labels=feature, axis='columns', inplace=True)\n",
    "\n",
    "feature = \"Day_Name\"\n",
    "can_drop.append(feature)\n",
    "train_data.drop(labels=feature, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_X_train = train_data.select_dtypes(exclude=['object'])\n",
    "y = drop_X_train.IsBadBuy\n",
    "X = drop_X_train.drop('IsBadBuy', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_object = list(train_data.select_dtypes(include=['object']).columns)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Make copy to avoid changing original data \n",
    "label_X_train = train_data.copy()\n",
    "#label_X_valid = X_valid.copy()\n",
    "\n",
    "# Apply label encoder to each column with categorical data\n",
    "label_encoder = LabelEncoder()\n",
    "for col in col_object:\n",
    "    label_X_train[col] = label_encoder.fit_transform(train_data[col])\n",
    "    #label_X_valid[col] = label_encoder.transform(X_valid[col])\n",
    "\n",
    "y = label_X_train.IsBadBuy\n",
    "X = label_X_train.drop('IsBadBuy', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in col_object:\n",
    "    print (col, \":  the number of unique data: \", len(train_data[col].unique()))\n",
    "    if (len(train_data[col].unique()) < 20):\n",
    "        print (train_data[col].unique())\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_object = list(train_data.select_dtypes(include=['object']).columns)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Apply one-hot encoder to each column with categorical data\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(train_data[col_object]))\n",
    "#OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[object_cols]))\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = train_data.index\n",
    "#OH_cols_valid.index = X_valid.index\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = train_data.drop(col_object, axis=1)\n",
    "#num_X_valid = X_valid.drop(object_cols, axis=1)\n",
    "\n",
    "# Add one-hot encoded columns to numerical features\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "#OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "\n",
    "y = OH_X_train.IsBadBuy\n",
    "X = OH_X_train.drop('IsBadBuy', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OH_X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "da3da259df43ee819735f558d677348c33641d49"
   },
   "source": [
    "###  Diving in (machine learning)\n",
    "\n",
    "<p>Now that the data has been cleaned, we can try to find a model that works well for making our predictions. We'll also load in some classifiers which we will compare.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Evaluate using train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1234567)\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "rfc.fit(X_train,y_train)\n",
    "\n",
    "# prediction on test set\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using \"cross_val_score\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc2 = RandomForestClassifier(n_estimators=100)\n",
    "rfc_cv_score = cross_val_score(rfc, X, y, cv=5, scoring='accuracy')\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Pipeline and cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "my_pipeline = Pipeline(steps=[('preprocessor', SimpleImputer()), ('model', RandomForestClassifier(n_estimators=100, random_state=1234567))])\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(my_pipeline, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "print(\"MAE scores:\\n\", scores)\n",
    "print(\"Average MAE score (across experiments):\")\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC = RandomForestClassifier()\n",
    "\n",
    "# Use kfold as our cross validation\n",
    "kfold = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Set grid search parameter settings\n",
    "#n_estimators = [int(x) for x in np.linspace(start = 20, stop = 200, num = 3)]\n",
    "n_estimators = [100]\n",
    "\n",
    "# max depth\n",
    "#max_depth = [int(x) for x in np.linspace(5, 50, num = 2)]\n",
    "#max_depth.append(None)\n",
    "max_depth = [None]\n",
    "\n",
    "rfc_param_grid = {'max_depth': max_depth, 'n_estimators': n_estimators}\n",
    "\n",
    "#rfc_param_grid = {'n_estimators': [100]}\n",
    "\n",
    "# Perform grid searches to get estimators with the optimal settings\n",
    "grid_search = GridSearchCV(estimator=RFC, param_grid=rfc_param_grid, n_jobs=1, cv=kfold, verbose=1)\n",
    "\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print (grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Read the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "bc1536a2d8fbce0795614d67d9205b4ab2baf132",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set has  (72983, 34)\n",
      "test set has  (48707, 33)\n",
      "remove one column from the training set\n",
      "merge training set and test set to all_data\n",
      "all_data has  (121690, 33)\n"
     ]
    }
   ],
   "source": [
    "# Read the data into dataframes\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('training.csv')\n",
    "print (\"training set has \", train_df.shape)\n",
    "test_df = pd.read_csv('test.csv')\n",
    "print (\"test set has \", test_df.shape)\n",
    "ntest = test_df.shape[0]\n",
    "\n",
    "print (\"remove one column from the training set\")\n",
    "print (\"merge training set and test set to all_data\")\n",
    "\n",
    "Ytrain = train_df['IsBadBuy']\n",
    "train_df = train_df.drop(columns=['IsBadBuy'])\n",
    "\n",
    "# Put all data together so we can wrangle all the data at the same time\n",
    "all_data = pd.concat([train_df, test_df], ignore_index=True)\n",
    "print (\"all_data has \", all_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 121690 entries, 0 to 121689\n",
      "Data columns (total 33 columns):\n",
      "RefId                                121690 non-null int64\n",
      "PurchDate                            121690 non-null object\n",
      "Auction                              121690 non-null object\n",
      "VehYear                              121690 non-null int64\n",
      "VehicleAge                           121690 non-null int64\n",
      "Make                                 121690 non-null object\n",
      "Model                                121690 non-null object\n",
      "Trim                                 117780 non-null object\n",
      "SubModel                             121677 non-null object\n",
      "Color                                121678 non-null object\n",
      "Transmission                         121678 non-null object\n",
      "WheelTypeID                          116333 non-null float64\n",
      "WheelType                            116328 non-null object\n",
      "VehOdo                               121690 non-null int64\n",
      "Nationality                          121678 non-null object\n",
      "Size                                 121678 non-null object\n",
      "TopThreeAmericanName                 121678 non-null object\n",
      "MMRAcquisitionAuctionAveragePrice    121662 non-null float64\n",
      "MMRAcquisitionAuctionCleanPrice      121662 non-null float64\n",
      "MMRAcquisitionRetailAveragePrice     121662 non-null float64\n",
      "MMRAcquisitonRetailCleanPrice        121662 non-null float64\n",
      "MMRCurrentAuctionAveragePrice        121232 non-null float64\n",
      "MMRCurrentAuctionCleanPrice          121232 non-null float64\n",
      "MMRCurrentRetailAveragePrice         121232 non-null float64\n",
      "MMRCurrentRetailCleanPrice           121232 non-null float64\n",
      "PRIMEUNIT                            5935 non-null object\n",
      "AUCGUART                             5935 non-null object\n",
      "BYRNO                                121690 non-null int64\n",
      "VNZIP1                               121690 non-null int64\n",
      "VNST                                 121690 non-null object\n",
      "VehBCost                             121690 non-null float64\n",
      "IsOnlineSale                         121690 non-null int64\n",
      "WarrantyCost                         121690 non-null int64\n",
      "dtypes: float64(10), int64(8), object(15)\n",
      "memory usage: 30.6+ MB\n"
     ]
    }
   ],
   "source": [
    "all_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5e14a4a6c7dc7d5fbd21e58e43d71256357733f4"
   },
   "source": [
    "###  Drop the unimportant features\n",
    "\n",
    "There are too many missing data in `PRIMEUNIT` and `AUCGUART`, so we can just remove these features.\n",
    "Also `RefId` has nothing to do but only the ID number that can be removed as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "b37b06030bc2581722bd2d98752e498fc5b6627f",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_data.drop(labels='AUCGUART', axis='columns', inplace=True)\n",
    "all_data.drop(labels='PRIMEUNIT', axis='columns', inplace=True)\n",
    "all_data.drop(labels='RefId', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with duplicated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([90880, 90886], dtype='int64')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[all_data.duplicated(keep=False)].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not duplicated data, that is good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Numeric Data\n",
    "###  Data histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Visualize the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PurchDate', 'Auction', 'Make', 'Model', 'Trim', 'SubModel', 'Color', 'Transmission', 'WheelType', 'Nationality', 'Size', 'TopThreeAmericanName', 'VNST']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7fcd2d72d860>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data_object = list(all_data.select_dtypes(include=[np.object]))\n",
    "print (data_object)\n",
    "\n",
    "import seaborn as sns\n",
    "g=sns.catplot(\"Make\", data = all_data, hue = \"Make\", kind = 'count', height=5, aspect=1.8,palette=\"winter\",legend_out=False)\n",
    "g.set_axis_labels(\"Make\", \"Count\")\n",
    "#sns.plt.title(\"Half time Score statistic\")\n",
    "#g.set(ylim=(0, 30))\n",
    "#g.despine(left=True)  \n",
    "#rc={'axes.labelsize': 16, 'font.size': 22.0, 'legend.fontsize': 16, 'axes.titlesize': 20}\n",
    "#sns.set(rc=rc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7e55734ef4c3fa2460d01deaa351113e66c5ee74"
   },
   "source": [
    "### Deal with missing values\n",
    "\n",
    "<p>Let's take a look at what missing values we'll have to handle.</p> For the numeric variable, replace null by median and for the category variable, most popular value is used to fill null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 121690 entries, 0 to 121689\n",
      "Data columns (total 30 columns):\n",
      "PurchDate                            121690 non-null object\n",
      "Auction                              121690 non-null object\n",
      "VehYear                              121690 non-null int64\n",
      "VehicleAge                           121690 non-null int64\n",
      "Make                                 121690 non-null object\n",
      "Model                                121690 non-null object\n",
      "Trim                                 121690 non-null object\n",
      "SubModel                             121690 non-null object\n",
      "Color                                121690 non-null object\n",
      "Transmission                         121690 non-null object\n",
      "WheelTypeID                          121690 non-null float64\n",
      "WheelType                            121690 non-null object\n",
      "VehOdo                               121690 non-null int64\n",
      "Nationality                          121690 non-null object\n",
      "Size                                 121690 non-null object\n",
      "TopThreeAmericanName                 121690 non-null object\n",
      "MMRAcquisitionAuctionAveragePrice    121690 non-null float64\n",
      "MMRAcquisitionAuctionCleanPrice      121690 non-null float64\n",
      "MMRAcquisitionRetailAveragePrice     121690 non-null float64\n",
      "MMRAcquisitonRetailCleanPrice        121690 non-null float64\n",
      "MMRCurrentAuctionAveragePrice        121690 non-null float64\n",
      "MMRCurrentAuctionCleanPrice          121690 non-null float64\n",
      "MMRCurrentRetailAveragePrice         121690 non-null float64\n",
      "MMRCurrentRetailCleanPrice           121690 non-null float64\n",
      "BYRNO                                121690 non-null int64\n",
      "VNZIP1                               121690 non-null int64\n",
      "VNST                                 121690 non-null object\n",
      "VehBCost                             121690 non-null float64\n",
      "IsOnlineSale                         121690 non-null int64\n",
      "WarrantyCost                         121690 non-null int64\n",
      "dtypes: float64(10), int64(7), object(13)\n",
      "memory usage: 27.9+ MB\n"
     ]
    }
   ],
   "source": [
    "all_isnull = all_data.columns[all_data.isnull().any()]\n",
    "for col in all_isnull:\n",
    "    try:\n",
    "        all_data[col].fillna(all_data[col].mode()[0], inplace=True)\n",
    "    except:\n",
    "        all_data[col].fillna(all_data[col].median(), inplace=True)\n",
    "all_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with category variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PurchDate', 'Auction', 'Make', 'Model', 'Trim', 'SubModel', 'Color', 'Transmission', 'WheelType', 'Nationality', 'Size', 'TopThreeAmericanName', 'VNST']\n",
      "PurchDate 519\n",
      "Auction 3\n",
      "['ADESA' 'OTHER' 'MANHEIM']\n",
      "Make 33\n",
      "['MAZDA' 'DODGE' 'FORD' 'MITSUBISHI' 'KIA' 'GMC' 'NISSAN' 'CHEVROLET'\n",
      " 'SATURN' 'CHRYSLER' 'MERCURY' 'HYUNDAI' 'TOYOTA' 'PONTIAC' 'SUZUKI'\n",
      " 'JEEP' 'HONDA' 'OLDSMOBILE' 'BUICK' 'SCION' 'VOLKSWAGEN' 'ISUZU'\n",
      " 'LINCOLN' 'MINI' 'SUBARU' 'CADILLAC' 'VOLVO' 'INFINITI' 'PLYMOUTH'\n",
      " 'LEXUS' 'ACURA' 'TOYOTA SCION' 'HUMMER']\n",
      "Model 1130\n",
      "Trim 137\n",
      "SubModel 933\n",
      "Color 17\n",
      "['RED' 'WHITE' 'MAROON' 'SILVER' 'BLACK' 'GOLD' 'GREY' 'BLUE' 'BEIGE'\n",
      " 'PURPLE' 'ORANGE' 'GREEN' 'BROWN' 'YELLOW' 'NOT AVAIL' 'OTHER' 'PINK']\n",
      "Transmission 3\n",
      "['AUTO' 'MANUAL' 'Manual']\n",
      "WheelType 3\n",
      "['Alloy' 'Covers' 'Special']\n",
      "Nationality 4\n",
      "['OTHER ASIAN' 'AMERICAN' 'TOP LINE ASIAN' 'OTHER']\n",
      "Size 12\n",
      "['MEDIUM' 'LARGE TRUCK' 'COMPACT' 'LARGE' 'VAN' 'MEDIUM SUV' 'LARGE SUV'\n",
      " 'SPECIALTY' 'SPORTS' 'CROSSOVER' 'SMALL SUV' 'SMALL TRUCK']\n",
      "TopThreeAmericanName 4\n",
      "['OTHER' 'CHRYSLER' 'FORD' 'GM']\n",
      "VNST 38\n",
      "['FL' 'VA' 'IA' 'AR' 'MN' 'TN' 'PA' 'OH' 'AL' 'MI' 'TX' 'IL' 'MA' 'AZ'\n",
      " 'GA' 'NC' 'MD' 'CA' 'UT' 'OR' 'SC' 'CO' 'ID' 'NV' 'WV' 'MS' 'OK' 'NM'\n",
      " 'LA' 'IN' 'MO' 'WA' 'NH' 'NJ' 'NY' 'NE' 'KY' 'WI']\n"
     ]
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "nonList = list(all_data.select_dtypes(include=[np.object]))\n",
    "print (nonList)\n",
    "\n",
    "all_data2 = all_data.copy()\n",
    "\n",
    "for this_label in nonList:\n",
    "    \n",
    "    encoder = ce.BinaryEncoder(cols=[this_label])\n",
    "    \n",
    "    all_data2 = encoder.fit_transform(all_data2)    \n",
    "    \n",
    "    print (this_label, len(all_data[this_label].unique()))\n",
    "    if (len(all_data[this_label].unique()) < 40):\n",
    "        print (all_data[this_label].unique())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "da3da259df43ee819735f558d677348c33641d49"
   },
   "source": [
    "###  Diving in (machine learning)\n",
    "\n",
    "<p>Now that the data has been cleaned, we can try to find a model that works well for making our predictions. We'll also load in some classifiers which we will compare.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "45e81048fd2b50e44ca687582f9900520d1e6392",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "Xtrain = all_data2.head(len(Ytrain))\n",
    "\n",
    "RFC = RandomForestClassifier()\n",
    "Ada = AdaBoostClassifier()\n",
    "KNN = KNeighborsClassifier()\n",
    "classifiers = [RFC, Ada, KNN]\n",
    "clf_names = ['Random Forest', 'AdaBoost', 'K Nearest Neighbors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2573510f0de967cf3741b0963345784f32caaa30"
   },
   "source": [
    "<p>For this analysis, we'll only be comparing across three classifiers: Random Forest, AdaBoost, and K Nearest Neighbors. For more information on other potential (or more complicated) classifiers I invite you to check out the other kernels posted by those who top the leaderboards for this competition.</p>\n",
    "\n",
    "<p>For each of these classifiers, we'll want to make sure we create the models with the optimal parameters. We can do this with a Grid Search. We define the set of parameters we want to scan for each type of classifier, and then run our grid searches.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a322b47a7dc1d0147ffbd3fcd3241366fe438af6"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n",
    "\n",
    "# Use kfold as our cross validation\n",
    "kfold = StratifiedKFold(n_splits=4)\n",
    "\n",
    "# Set grid search parameter settings\n",
    "rfc_param_grid = {'max_depth': [None],\n",
    "                 'max_features': [1],\n",
    "                 'min_samples_split': [2],\n",
    "                 'min_samples_leaf': [1],\n",
    "                 'bootstrap': [False],\n",
    "                 'n_estimators': [100],\n",
    "                 'criterion': ['gini']}\n",
    "ada_param_grid = {'n_estimators': [20],\n",
    "                 'learning_rate': [0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "knn_param_grid = {'n_neighbors': [5],\n",
    "                  'weights': ['uniform', 'distance'],\n",
    "                 'leaf_size': [5]}\n",
    "param_grids = [rfc_param_grid, ada_param_grid, knn_param_grid]\n",
    "\n",
    "# Perform grid searches to get estimators with the optimal settings\n",
    "grid_searches = []\n",
    "for i in range(len(classifiers)):\n",
    "    grid_searches.append(GridSearchCV(estimator=classifiers[i], param_grid=param_grids[i], \n",
    "                                      n_jobs=4, cv=kfold, verbose=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d632d4a7bf7c566b139aa09ac56d12cbfdf10116"
   },
   "source": [
    "<p>We'll now want to see the training scores for each of our models and determine which one works the best. We'll fit each model to our training set and add the best scores from each to a list.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9f8452618656ef1a841d1a7ce1f69478f0d963ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:   40.2s remaining:   40.2s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   40.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "# Train the models\n",
    "best_scores = []\n",
    "for i in range(len(grid_searches)):\n",
    "    grid_searches[i].fit(Xtrain, Ytrain)\n",
    "    best_scores.append(grid_searches[i].best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f499d641ff0414737da2c8e64339934c034dd968"
   },
   "source": [
    "<p>Let's see the best scores for each classifier.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "242a20ab1d09bd77b8082086be53cff9c12ce541"
   },
   "outputs": [],
   "source": [
    "# Best scores\n",
    "for i in range(len(best_scores)):\n",
    "    print(clf_names[i] + \": \" + str(best_scores[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "763ba583c7e203ca3d44f39ce89cfd6d7c0c0e5a"
   },
   "source": [
    "<p>Based on these training scores, it makes the most sense to use the Random Forest Classifier to make the predictions. We'll predict on the test set, and then write the predictions to a csv file for submission.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b3ca1c1802687ab5e165f0dfcbcc4e06a574604f"
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "Xtest = all_data2.tail(ntest)\n",
    "#Xtest = test_df.drop(columns='RefId', axis='columns')\n",
    "predictions = grid_searches[0].predict(Xtest)\n",
    "\n",
    "# Write predictions to output csv\n",
    "pred_df = pd.DataFrame({'RefId': test_df['RefId'],\n",
    "                        'IsBadBuy': predictions})\n",
    "pred_df.to_csv('predictions.csv', index=False)\n",
    "\n",
    "print(\"Done writing to csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
